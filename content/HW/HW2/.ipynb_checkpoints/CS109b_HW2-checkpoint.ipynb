{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "## Homework 2 - Clustering\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2021**<br/>\n",
    "**Instructors**: Mark Glickman, Pavlos Protopapas, & Chris Tanner \n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Homework 2 is due February 17th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PLEASE RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- This is individual homework - No collaboration/Groups\n",
    "\n",
    "- To submit your assignment, please follow the instructions on Canvas.\n",
    "\n",
    "- Please restart the kernel and run the entire notebook again before you submit. Running cells out of order is a common pitfall in Jupyter Notebooks.\n",
    "\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports statement at the top of this notebook. We strongly suggest that you use those and not others as we may not be familiar with them.\n",
    "\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**. \n",
    "\n",
    "- In questions that require code to answer, such as \"calculate the $R^2$\", do not just output the value from a cell. Write a `print()` function that includes a reference to the calculated value, **not hardcoded**. For example:\n",
    "```python\n",
    "print(f'The R^2 is {R:.4f}')\n",
    "```\n",
    "- Your plots should be clearly labeled, including clear labels for the $x$ and $y$ axes as well as a descriptive title (\"MSE plot\" is not a descriptive title; \"95% confidence interval of coefficients of polynomial degree 5\" is).\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Please use the libraries below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import scipy.cluster.hierarchy as hac\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import fcluster\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import silhouette_samples, silhouette_score\n",
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from gap_statistic import OptimalK\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "# Notebook Contents\n",
    "\n",
    "- [**Problem 1 [37.5 pts]: Clustering with k-means**](#part1)\n",
    "\n",
    "- [**Problem 2 [37.5 pts]: Other Ks**](#part2)\n",
    "  \n",
    "- [**Problem 3 [25 pts]: Alternative Algorithms**](#part3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class=\"theme\">FMA: A Dataset For Music Analysis </div>\n",
    "\n",
    "\n",
    "In this assignment, you will be working with data collected from The Free Music Archive (https://freemusicarchive.org/). The Free Music Archive is an online repository of original music from independent artists that can be freely downloaded. Each audio file (encoded as mp3) was then reduced into summary audio features using the librosa python package.\n",
    "\n",
    "\n",
    "The dataset `fma.csv` contains 20,000 rows and 63 columns. Each row corresponds to the audio metadata for one music track. The metadata consists of nine audio features computed across time and summarized:\n",
    "\n",
    "`1. Chroma, 7 attributes`\n",
    "\n",
    "`2. Tonnetz, 7 attributes`\n",
    "\n",
    "`3. Mel Frequency Cepstral Coefficient (MFCC), 7 attributes`\n",
    "\n",
    "`4. Spectral centroid, 7 attributes`\n",
    "\n",
    "`5. Spectral bandwidth, 7 attributes`\n",
    "\n",
    "`6. Spectral contrast, 7 attributes`\n",
    "\n",
    "`7. Spectral rolloff, 7 attributes`\n",
    "\n",
    "`8. Root Mean Square energy, 7 attributes`\n",
    "\n",
    "`9. Zero-crossing rate, 7 attributes`\n",
    "\n",
    "For those interestend in more information about the FMA dataset please see the paper and GitHub repository (https://github.com/mdeff/fma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id=\"part1\"></a>\n",
    "\n",
    "## <div class='exercise'>Problem 1: Clustering with k-means </div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**1.1**  Start by reading the dataset into a pandas data frame. The FMA website includes 16 different music genres so we will begin by trying 16 clusters. Normalize the dataset then run the k-means clustering algorithm, using the `KMeans` class from sklearn.cluster, with the number of clusters corresponding to 16, `n_init` of 46, and 109 as the random seed. Add the result as a new column called `Cluster16` to your data frame.\n",
    "\n",
    "**1.2**  Use the function provided to visualize the results for k-means on a random sample of 2,000 observations (it will take the sample for you). Does 16 clusters seem to make sense?\n",
    "\n",
    "**1.3** Plot the silhouette scores using the function below, from lecture. Give it a 10% sample of the data to speed the visualization. How reasonable does the clustering seem based on this plot? How does it compare to the information in the plot above?\n",
    "\n",
    "**1.4** The FMA website also includes 4 different recording types (album, live recording, radio program, or single track). Repeat all of the above steps, but with the number of clusters corresponding to 4. That is : \n",
    "\n",
    "- Run the k-means algorithm with 4 centroids instead of 16, creating a variable named `Cluster4` and adding it to the dataset. \n",
    "\n",
    "- Visualize the results for k-means. Does 4 clusters seem to make sense from this plot?\n",
    "\n",
    "- Plot the silhouette scores on a 10% sample of the data. How reasonable does the clustering seem based on this plot?\n",
    "\n",
    "**1.5** What do the results suggest? Does this make sense in the context of what we know about the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Problem 1: Answers\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.1**  Start by reading the dataset into a pandas data frame. The FMA website includes 16 different music genres so we will begin by trying 16 clusters. Normalize the dataset then run the k-means clustering algorithm, using the `KMeans` class from sklearn.cluster, with the number of clusters corresponding to 16, `n_init` of 46, and 109 as the random seed. Add the result as a new column called `Cluster16` to your data frame.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "data = pd.read_csv('data/fma.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.2**  Use the function provided to visualize the results for k-means on a random sample of 2,000 observations (it will take the sample for you). Does 16 clusters seem to make sense?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "def plot_clusters(full_data, group_col):\n",
    "    \n",
    "    # seperate features only from cluster labels\n",
    "    feature_columns = [colname for colname in list(full_data.columns) if 'Cluster' not in colname]\n",
    "    features_only = full_data[feature_columns]\n",
    "\n",
    "    # fit PCA to the whole data\n",
    "    fitted_pca = PCA().fit(features_only)\n",
    "\n",
    "    # take a sample of the whole data\n",
    "    df_sample = features_only.sample(2000, random_state=109)\n",
    "\n",
    "    # apply the PCA transform on the sample\n",
    "    pca_sample = pd.DataFrame(fitted_pca.transform(df_sample), columns = [\"PCA{}\".format(i) for i in range(len(df_sample.columns.values))])\n",
    "    pca_sample.index = df_sample.index\n",
    "    \n",
    "    # re-include a cluster label for the pca data\n",
    "    pca_sample[group_col] = full_data.loc[pca_sample.index, group_col]\n",
    "    \n",
    "    plt.figure(figsize=(11,8.5))\n",
    "    marker_types = [\".\", \"v\", \"1\", \"^\", \"s\", \"p\", \"P\", \"3\", \"H\", \"<\", \"|\", \"_\", \"x\", \"*\",\"d\",\"X\"]\n",
    "    marker_colors = np.concatenate([np.array(plt.cm.tab10.colors),np.array(plt.cm.Pastel1.colors)])\n",
    "    \n",
    "    for i, (cluster_id, cur_df) in enumerate(pca_sample.groupby([group_col])):\n",
    "\n",
    "        pca1_scores = cur_df.iloc[:,0]\n",
    "        pca2_scores = cur_df.iloc[:,1]\n",
    "        plt.scatter(pca1_scores, pca2_scores, label=cluster_id, c=marker_colors[i].reshape(1,-1), marker=marker_types[i])\n",
    "\n",
    "    plt.xlabel(\"PC1 ({}%)\".format(np.round(100*fitted_pca.explained_variance_ratio_[0],1)))\n",
    "    plt.ylabel(\"PC2 ({}%)\".format(np.round(100*fitted_pca.explained_variance_ratio_[1],1)))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return pca_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.3** Plot the silhouette scores using the function below, from lecture. Give it a 10% sample of the data to speed the visualization. How reasonable does the clustering seem based on this plot? How does it compare to the information in the plot above?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "#modified code from http://scikit-learn.org/stable/auto_examples/cluster/plot_kmeans_silhouette_analysis.html\n",
    "\n",
    "def silplot(X, cluster_labels, clusterer, pointlabels=None):\n",
    "    n_clusters = clusterer.n_clusters\n",
    "    \n",
    "    # Create a subplot with 1 row and 2 columns\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2)\n",
    "    fig.set_size_inches(11,8.5)\n",
    "\n",
    "    # The 1st subplot is the silhouette plot\n",
    "    # The silhouette coefficient can range from -1, 1 but in this example we \n",
    "    # will set a limit\n",
    "    ax1.set_xlim([-0.2, 1])\n",
    "    \n",
    "    # The (n_clusters+1)*10 is for inserting blank space between silhouette\n",
    "    # plots of individual clusters, to demarcate them clearly.\n",
    "    ax1.set_ylim([0, len(X) + (n_clusters + 1) * 10])\n",
    "\n",
    "    # The silhouette_score gives the average value for all the samples.\n",
    "    # This gives a perspective into the density and separation of the formed\n",
    "    # clusters\n",
    "    silhouette_avg = silhouette_score(X, cluster_labels)\n",
    "    print(\"For n_clusters = \", n_clusters,\n",
    "          \", the average silhouette_score is \", silhouette_avg,\".\",sep=\"\")\n",
    "\n",
    "    # Compute the silhouette scores for each sample\n",
    "    sample_silhouette_values = silhouette_samples(X, cluster_labels)\n",
    "\n",
    "    y_lower = 10\n",
    "    for i in range(0,n_clusters+1):\n",
    "        # Aggregate the silhouette scores for samples belonging to\n",
    "        # cluster i, and sort them\n",
    "        ith_cluster_silhouette_values = \\\n",
    "            sample_silhouette_values[cluster_labels == i]\n",
    "\n",
    "        ith_cluster_silhouette_values.sort()\n",
    "\n",
    "        size_cluster_i = ith_cluster_silhouette_values.shape[0]\n",
    "        y_upper = y_lower + size_cluster_i\n",
    "\n",
    "        color = cm.nipy_spectral(float(i) / n_clusters)\n",
    "        ax1.fill_betweenx(np.arange(y_lower, y_upper),\n",
    "                          0, ith_cluster_silhouette_values,\n",
    "                          facecolor=color, edgecolor=color, alpha=0.7)\n",
    "\n",
    "        # Label the silhouette plots with their cluster numbers at the middle\n",
    "        ax1.text(-0.05, y_lower + 0.5 * size_cluster_i, str(i))\n",
    "\n",
    "        # Compute the new y_lower for next plot\n",
    "        y_lower = y_upper + 10  # 10 for the 0 samples\n",
    "\n",
    "    ax1.set_title(\"The silhouette plot for the various clusters.\")\n",
    "    ax1.set_xlabel(\"The silhouette coefficient values\")\n",
    "    ax1.set_ylabel(\"Cluster label\")\n",
    "\n",
    "    # The vertical line for average silhouette score of all the values\n",
    "    ax1.axvline(x=silhouette_avg, color=\"red\", linestyle=\"--\")\n",
    "\n",
    "    ax1.set_yticks([])  # Clear the yaxis labels / ticks\n",
    "    ax1.set_xticks([-0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])\n",
    "\n",
    "    # 2nd Plot showing the actual clusters formed\n",
    "    colors = cm.nipy_spectral(cluster_labels.astype(float) / n_clusters)\n",
    "    \n",
    "    # axes will be first 2 PCA components\n",
    "    \n",
    "    pca = PCA(n_components=2).fit(X)\n",
    "    X_pca = pca.transform(X) \n",
    "    ax2.scatter(X_pca[:, 0], X_pca[:, 1], marker='.', s=200, lw=0, alpha=0.7,\n",
    "                c=colors, edgecolor='k')\n",
    "    xs = X_pca[:, 0]\n",
    "    ys = X_pca[:, 1]    \n",
    "\n",
    "    \n",
    "    if pointlabels is not None:\n",
    "        for i in range(len(xs)):\n",
    "            plt.text(xs[i],ys[i],pointlabels[i])\n",
    "\n",
    "    # Labeling the clusters (transform to PCA space for plotting)\n",
    "    centers = pca.transform(clusterer.cluster_centers_)\n",
    "    # Draw white circles at cluster centers\n",
    "    ax2.scatter(centers[:, 0], centers[:, 1], marker='o',\n",
    "                c=\"white\", alpha=1, s=200, edgecolor='k')\n",
    "\n",
    "    for i, c in enumerate(centers):\n",
    "        ax2.scatter(c[0], c[1], marker='$%d$' % int(i), alpha=1,\n",
    "                    s=50, edgecolor='k')\n",
    "\n",
    "    ax2.set_title(\"The visualization of the clustered data.\")\n",
    "    ax2.set_xlabel(\"PC1\")\n",
    "    ax2.set_ylabel(\"PC2\")\n",
    "\n",
    "    plt.suptitle((\"Silhouette analysis for KMeans clustering on sample data \"\n",
    "                  \"with n_clusters = %d\" % n_clusters),\n",
    "                 fontsize=14, fontweight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.4",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.4** The FMA website also includes 4 different recording types (album, live recording, radio program, or single track). Repeat all of the above steps, but with the number of clusters corresponding to 4. That is :\n",
    "\n",
    "- Run the k-means algorithm with 4 centroids instead of 16, creating a variable named `Cluster4` and adding it to the dataset.\n",
    "\n",
    "- Visualize the results for k-means. Does 4 clusters seem to make sense from this plot?\n",
    "\n",
    "- Plot the silhouette scores on a 10% sample of the data. How reasonable does the clustering seem based on this plot?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.5",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.5** What do the results suggest? Does this make sense in the context of what we know about the problem?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id=\"part2\"></a>\n",
    "\n",
    "## <div class='exercise'>Problem 2: Other Ks </div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "In the previous problem, we examined the results of running k-means with 4 and 16 centroids on the fma data. In this problem, we will investigate a broader range of possible cluster sizes, with a borader range of metrics. \n",
    "\n",
    "**For all of these questions, you should work with a sample of 2,000 data points drawn with `pd.sample` and a random seed of 109.**\n",
    "\n",
    "**2.1** Use the elbow method to evaluate the best choice of the number of clusters, plotting the total within-cluster variation against the number of clusters, for k-means clustering with $k \\in \\{1,2,...,20\\}.$\n",
    "\n",
    "**2.2** Use the average silhouette to evaluate the choice of the number of clusters for k-means clustering with $k \\in \\{1,2,...,20\\}$. Plot the results. \n",
    "\n",
    "**2.3** Use the gap statistic to evaluate the choice of the number of clusters for k-means clustering with $k \\in \\{1,2,..,20\\}$. Plot the results. \n",
    "\n",
    "**2.4** After analyzing the plots produced by all three of these measures, discuss the number of k-means clusters that you think is the best fit for this dataset. Defend your answer with evidence from the previous parts of this question, the three graphs produced here, and what you surmise about this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Problem 2: Answers\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.1** Use the elbow method to evaluate the best choice of the number of clusters, plotting the total within-cluster variation against the number of clusters, for k-means clustering with $k \\in \\{1,2,...,20\\}.$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.2** Use the average silhouette to evaluate the choice of the number of clusters for k-means clustering with $k \\in \\{1,2,...,20\\}$. Plot the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.3** Use the gap statistic to evaluate the choice of the number of clusters for k-means clustering with $k \\in \\{1,2,..,20\\}$. Plot the results.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.4",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.4** After analyzing the plots produced by all three of these measures, discuss the number of k-means clusters that you think is the best fit for this dataset. Defend your answer with evidence from the previous parts of this question, the three graphs produced here, and what you surmise about this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<a id=\"part3\"></a>\n",
    "\n",
    "## <div class='exercise'>Problem 3: Alternative Algorithms </div>\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**3.1** Create a knee plot to determine an optimal epsilon then run DBSCAN on the data. How many clusters are found, and how well does this clustering perform on e.g. silhouette score, excluding the points not assigned to any cluster?  \n",
    "*Note*: Do not use a sample of the data. This may take a few minutes to run.\n",
    "\n",
    "**3.2** Hierarchical clustering. Run agglomerative clustering (using Ward's method), and plot the result using a dendrogram. Interpret the results, and describe the cluster size(s) the plot suggests. What level of aggregation is suggested by the sihoutte score?\n",
    "\n",
    "**3.3** Overall, what do you conclude about the number and kind of clusters in this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Problem 3: Answers\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**3.1** Create a knee plot to determine an optimal epsilon then run DBSCAN on the data. How many clusters are found, and how well does this clustering perform on e.g. silhouette score, excluding the points not assigned to any cluster?\n",
    "*Note*: Do not use a sample of the data. This may take a few minutes to run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**3.2** Hierarchical clustering. Run agglomerative clustering (using Ward's method), and plot the result using a dendrogram. Interpret the results, and describe the cluster size(s) the plot suggests. What level of aggregation is suggested by the sihoutte score?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "3.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**3.3** Overall, what do you conclude about the number and kind of clusters in this data set?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
