{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5a-ez4gTtO4G"
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "\n",
    "## Homework 5 - Recurrent Neural Networks\n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2021**<br/>\n",
    "**Instructors**: Mark Glickman, Pavlos Protopapas, and Chris Tanner\n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 17
    },
    "id": "FEd5FB3-tO4S",
    "outputId": "a696fe58-aa81-411a-b104-ba93cf36bc54"
   },
   "outputs": [],
   "source": [
    "#RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\n",
    "    \"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/\"\n",
    "    \"content/styles/cs109.css\"\n",
    ").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7nu_B30xtO4U"
   },
   "source": [
    "<hr style=\"height:2pt\">\n",
    "\n",
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment follow the instructions given in Canvas.\n",
    "\n",
    "- Please restart the kernel and run the entire notebook again before you submit.\n",
    "\n",
    "- Running cells out of order is a common pitfall in Jupyter Notebooks. To make sure your code works restart the kernel and run the whole notebook again before you submit. \n",
    "\n",
    "- We have tried to include all the libraries you may need to do the assignment in the imports cell provided below. **Please use only the libraries provided in those imports.**\n",
    "\n",
    "- Please use .head() when viewing data. Do not submit a notebook that is **excessively long**. \n",
    "\n",
    "- In questions that require code to answer, such as \"calculate the $R^2$\", do not just output the value from a cell. Write a `print()` function that clearly labels the output, includes a reference to the calculated value, and rounds it to a reasonable number of digits. **Do not hard code values in your printed output**. For example, this is an appropriate print statement:\n",
    "```python\n",
    "print(f\"The R^2 is {R:.4f}\")\n",
    "```\n",
    "- Your plots should be clearly labeled, including clear labels for the $x$ and $y$ axes as well as a descriptive title (\"MSE plot\" is NOT a descriptive title; \"95% confidence interval of coefficients of polynomial degree 5\" on the other hand is descriptive).\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bguOP1aCtO4a",
    "outputId": "495f94e1-b64f-44ab-8427-f6b4c309f5b9"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend\n",
    "from tensorflow.keras import Model, Sequential\n",
    "from tensorflow.keras.layers import Input, SimpleRNN, Embedding, Dense, \\\n",
    "                            TimeDistributed, GRU, Dropout, Bidirectional, \\\n",
    "                            Conv1D, BatchNormalization\n",
    "from tensorflow.keras.models import model_from_json\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "plt.style.use(\"tableau-colorblind10\")\n",
    "\n",
    "print(f\"Using TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Using TensorFlow Keras version: {tf.keras.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9p5dQ-YO4x54",
    "outputId": "2c76af8a-4d9a-4caa-a2d8-08457d7cd08b"
   },
   "outputs": [],
   "source": [
    "devices = tf.config.experimental.get_visible_devices()\n",
    "print(f\"Devices: {devices}\\n\")\n",
    "print(\n",
    "    f\"Logical Devices: {tf.config.experimental.list_logical_devices('GPU')}\\n\"\n",
    ")\n",
    "\n",
    "print(f\"GPU Available: {tf.config.list_physical_devices('GPU')}\\n\")\n",
    "print(f\"All Pysical Devices: {tf.config.list_physical_devices()}\")\n",
    "\n",
    "# Set seed for repeatable results\n",
    "np.random.seed(123)\n",
    "tf.random.set_seed(456)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dqmE4CjktO4f"
   },
   "source": [
    "<a id=\"contents\"></a>\n",
    "\n",
    "## Notebook Contents\n",
    "\n",
    "- [**PART 1 [ 22 pts ]: Data**](#part1)\n",
    "  - [Overview](#part1intro)\n",
    "  - [Questions](#part1questions)\n",
    "  - [Solutions](#part1solutions)\n",
    "\n",
    "\n",
    "- [**PART 2 [ 38 pts ]: Modelling**](#part2)\n",
    "  - [Overview](#part2intro)\n",
    "  - [Questions](#part2questions)\n",
    "  - [Solutions](#part2solutions)\n",
    "\n",
    "\n",
    "- [**PART 3 [ 40 pts ]: Analysis**](#part3)\n",
    "  - [Overview](#part3intro)\n",
    "  - [Questions](#part3questions)\n",
    "  - [Solutions](#part3solutions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "unXusMi5tO4i"
   },
   "source": [
    "## About this Homework\n",
    "\n",
    "### The named entity recognition challenge!\n",
    "\n",
    "[**Named entity recognition (NER)**](https://en.wikipedia.org/wiki/Named-entity_recognition) seeks to locate and classify named entities present in unstructured text into predefined categories such as organizations, locations, expressions of times, names of persons, etc. This technique is often used in real use cases such as classifying content for news providers, efficient search algorithms over large corpora, and content-based recommendation systems. \n",
    "\n",
    "NER represents an interesting \"many-to-many\" problem, and in this homework, it allows us to experiment with recurrent architectures and compare their performances against other models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "quPL0bhWtO4i"
   },
   "source": [
    "<a id=\"part1\"></a>\n",
    "    \n",
    "<!-- <div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\"> -->\n",
    "\n",
    "# PART 1 [ 22 pts ]: Data\n",
    "\n",
    "[Return to contents](#contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ePZfwJmtO4k"
   },
   "source": [
    "<a id=\"part1intro\"></a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "**First, we will read `data/HW5_data.csv` into a pandas dataframe using the code provided below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 520
    },
    "id": "--u4YXOotO4l",
    "outputId": "d370ceff-44e3-40f4-c1c8-643cfc9b6401"
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL\n",
    "datapath = \"./data/HW5_data.csv\"\n",
    "data = pd.read_csv(datapath, encoding=\"latin1\")\n",
    "data = data.fillna(method=\"ffill\")\n",
    "data.head(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RqhTwPo5tO4p"
   },
   "source": [
    "**As you can see above,** we have a dataset with sentences (as indicated by the `Sentence #` column), each composed of words (shown in the `Word` column) with part-of-speech tagging (shown in the `POS` tagging column) and inside–outside–beginning (IOB) named entity tags attached (shown in the `Tag` column). **`POS` will NOT be used for this homework. We will predict `Tag` using only the words themselves.**\n",
    "\n",
    "**Essential info about entities:**\n",
    "\n",
    "* geo = Geographical Entity\n",
    "* org = Organization\n",
    "* per = Person\n",
    "* gpe = Geopolitical Entity\n",
    "* tim = Time indicator\n",
    "* art = Artifact\n",
    "* eve = Event\n",
    "* nat = Natural Phenomenon\n",
    "\n",
    "**IOB prefix:**\n",
    "\n",
    "* B: beginning of named entity\n",
    "* I: inside of named entity\n",
    "* O: outside of named entity\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-gZQLtQAtO4t"
   },
   "source": [
    "<a id=\"part1questions\"></a>\n",
    "\n",
    "### <div class='exercise'>PART 1: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n",
    "\n",
    "<a id=\"q11\"></a>\n",
    "\n",
    "**[1.1:](#s11)** Create a list of unique words found in the `Word` column and sort it in alphabetic order (do not modify the word capitalization, nor remove any numeric or special characters). Then append the special word `\"ENDPAD\"` to the end of the list, and assign it to the variable `words`. Store the length of this list as `n_words`. **Print your results for `n_words`**\n",
    "\n",
    "<a id=\"q12\"></a>\n",
    "\n",
    "**[1.2:](#s12)** Create a list of unique tags and sort it in alphabetic order. Then append the special word `\"PAD\"` to the end of the list, and assign it to the variable `tags`. Store the length of this list as `n_tags`. **Print your results for `n_tags`**\n",
    "\n",
    "<a id=\"q13\"></a>\n",
    "\n",
    "**[1.3:](#s13)** Create a list of lists where each sentence in the data is a list of `(word, tag)` tuples. Here is an example of how the first sentence in the list should look:\n",
    "\n",
    "```\n",
    "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'),\n",
    "('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'),\n",
    "('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'),\n",
    "('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), \n",
    "('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'),\n",
    "('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n",
    "```\n",
    "\n",
    "<a id=\"q14\"></a>\n",
    "\n",
    "**[1.4:](#s14)**  Find out the number of words in the longest sentence, and store it to variable `max_len`. **Print your results for `max_len`.**\n",
    "\n",
    "<a id=\"q15\"></a>\n",
    "\n",
    "**[1.5:](#s15)** It is now time to convert the sentences data in a suitable format for our RNN training and evaluation procedures. Create a `word2idx` dictionary that maps distinct words from the dataset into distinct integers. Also create an `idx2word` dictionary.\n",
    "\n",
    "<a id=\"q16\"></a>\n",
    "\n",
    "**[1.6:](#s16)** Prepare the predictors matrix `X` as a list of lists, where each inner list is a sequence of words mapped into integers according to the `word2idx` dictionary. \n",
    "\n",
    "<a id=\"q17\"></a>\n",
    "\n",
    "**[1.7:](#s17)** Apply the Keras `pad_sequences` function to create standard length observations. You should retrieve a matrix with all padded sentences and length equal to the `max_len` previously computed. The dimensionality of your resulting `X` matrix should therefore be equal to `(# of sentences, max_len)`. Run the provided cell to print your results. Your `X[i]` now should be something similar to this:\n",
    "\n",
    "```\n",
    " [ 8193 27727 31033 33289 22577 33464 23723 16665 33464 31142 31319 28267\n",
    " 27700 33246 28646 16052    21 16915 17349  7924 32879 32985 18238 23555\n",
    "    24 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178]\n",
    "```\n",
    " \n",
    "<a id=\"q18\"></a>\n",
    "\n",
    "**[1.8:](#s18)** Create a `tag2idx` dictionary mapping distinct named entity tags from the dataset into distinct integers. Also create a `idx2tag` dictionary.\n",
    "\n",
    "<a id=\"q19\"></a>\n",
    "\n",
    "**[1.9:](#s19)** Prepare the targets matrix `Y` as a list of lists, where each inner list is a sequence of tags mapped into integers according to the `tag2idx` dictionary.\n",
    "\n",
    "<a id=\"q110\"></a>\n",
    "\n",
    "**[1.10:](#s110)** Apply the Keras `pad_sequences` function to standardize the targets. Inject the `PAD` tag integer value for the padding words. Your result should be a `Y` matrix with all padded sentences' tags and length equal to the `max_len` previously computed. \n",
    "\n",
    "<a id=\"q111\"></a>\n",
    "\n",
    "**[1.11:](#s111)** Use the Keras `to_categorical` function to one-hot-encode the tags. The dimensionality of your resulting `Y` matrix should be equal to `(# of sentences, max_len, n_tags)`. Run the provided cell to print your results.\n",
    "\n",
    "<a id=\"q112\"></a>\n",
    "\n",
    "**[1.12:](#s112)** Split the dataset into train and test sets with a 10% test split using `109` for your random state. Assign your training data to the variables `X_tr` and `y_tr` and your test data to the variables `X_te` and `y_te`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBtmANNuuS6h"
   },
   "source": [
    "<a id=\"part1solutions\"></a>\n",
    "\n",
    "## PART 1: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZjRcvLV-tO4v"
   },
   "source": [
    "<a id=\"s11\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.1:](#q11)** Create a list of unique words found in the `Word` column and sort it in alphabetic order (do not modify the word capitalization, nor remove any numeric or special characters). Then append the special word `\"ENDPAD\"` to the end of the list, and assign it to the variable `words`. Store the length of this list as `n_words`. **Print your results for `n_words`**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NbLiCEgEtO4w",
    "outputId": "915e6e6a-06ab-44c4-91c4-5cd650def731"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KHAhH-sXtO4z",
    "outputId": "a4b56e80-7729-4235-a93e-603e47f408b1"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results for n_words\n",
    "print(\"There are {:,} unique words found in our dataset.\".format(n_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "khIqw5BLtO41"
   },
   "source": [
    "<a id=\"s12\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.2:](#q12)** Create a list of unique tags and sort it in alphabetic order. Then append the special word `\"PAD\"` to the end of the list, and assign it to the variable `tags`. Store the length of this list as `n_tags`. **Print your results for `n_tags`**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nTEvzpwGtO42"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Idh1V7CytO43",
    "outputId": "3ef8c837-e2a6-483f-bfdc-bf3f367e6ca2"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results for n_tags\n",
    "print(\"There are {} unique tags found in our dataset.\".format(n_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qkkSbILitO44"
   },
   "source": [
    "<a id=\"s13\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.3:](#q13)** Create a list of lists where each sentence in the data is a list of `(word, tag)` tuples. Here is an example of how the first sentence in the list should look:\n",
    "\n",
    "```\n",
    "[('Thousands', 'O'), ('of', 'O'), ('demonstrators', 'O'), ('have', 'O'),\n",
    "('marched', 'O'), ('through', 'O'), ('London', 'B-geo'), ('to', 'O'),\n",
    "('protest', 'O'), ('the', 'O'), ('war', 'O'), ('in', 'O'),\n",
    "('Iraq', 'B-geo'), ('and', 'O'), ('demand', 'O'), ('the', 'O'), \n",
    "('withdrawal', 'O'), ('of', 'O'), ('British', 'B-gpe'), ('troops', 'O'),\n",
    "('from', 'O'), ('that', 'O'), ('country', 'O'), ('.', 'O')]\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0bXJ13E8tO45",
    "outputId": "9aa119ef-52bb-4025-deb1-5872df4aed31"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0XTS_EutO47"
   },
   "source": [
    "<a id=\"s14\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.4:](#q14)** Find out the number of words in the longest sentence, and store it to variable `max_len`. **Print your results for `max_len`.**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m2XHfkKWtO4-"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E77nyGbXtO4_",
    "outputId": "62bd1fd0-4268-437d-ee47-cfc379d0a2e5"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results for max_len\n",
    "print(\"The number of words in our longest sentence is: {}\".format(max_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GO-shDtvtO5B"
   },
   "source": [
    "<a id=\"s15\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.5:](#q15)** It is now time to convert the sentences data in a suitable format for our RNN training and evaluation procedures. Create a `word2idx` dictionary that maps distinct words from the dataset into distinct integers. Also create an `idx2word` dictionary.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k7YpPc3ftO5C"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lDOa_vbqtO5C"
   },
   "source": [
    "<a id=\"s16\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.6:](#q16)** Prepare the predictors matrix `X` as a list of lists, where each inner list is a sequence of words mapped into integers according to the `word2idx` dictionary.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zk3cNnGUtO5D"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3qLvSnV4tO5F"
   },
   "source": [
    "<a id=\"s17\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.7:](#q17)** Apply the Keras `pad_sequences` function to create standard length observations. You should retrieve a matrix with all padded sentences and length equal to the `max_len` previously computed. The dimensionality of your resulting `X` matrix should therefore be equal to `(# of sentences, max_len)`. Run the provided cell to print your results. Your `X[i]` now should be something similar to this:\n",
    "\n",
    "```\n",
    " [ 8193 27727 31033 33289 22577 33464 23723 16665 33464 31142 31319 28267\n",
    " 27700 33246 28646 16052    21 16915 17349  7924 32879 32985 18238 23555\n",
    "    24 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178 35178\n",
    " 35178 35178 35178 35178 35178 35178 35178 35178]\n",
    "```\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pJYw3VTWtO5F"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MxDMT030tO5G",
    "outputId": "f0de4686-eabd-4b57-c248-353139023ae0"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "print(\"The index of word 'Harvard' is: {}\\n\".format(word2idx[\"Harvard\"]))\n",
    "print(\"Sentence 1: {}\\n\".format(X[1]))\n",
    "print(\"The shape of the X array is: {}\".format(X.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X5U-dY8htO5I"
   },
   "source": [
    "<a id=\"s18\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.8:](#q18)** Create a `tag2idx` dictionary mapping distinct named entity tags from the dataset into distinct integers. Also create a `idx2tag` dictionary.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HFYq42y8tO5J"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j5Zvo7xMtO5L"
   },
   "source": [
    "<a id=\"s19\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.9:](#q19)** Prepare the targets matrix `Y` as a list of lists, where each inner list is a sequence of tags mapped into integers according to the `tag2idx` dictionary.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "M9TRw2fdtO5M"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mcIyIavCtO5N"
   },
   "source": [
    "<a id=\"s110\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.10:](#q110)** Apply the Keras `pad_sequences` function to standardize the targets. Inject the `PAD` tag integer value for the padding words. Your result should be a `Y` matrix with all padded sentences' tags and length equal to the `max_len` previously computed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DYvFmiYetO5N"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SzZWq9N_tO5Q"
   },
   "source": [
    "<a id=\"s111\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.11:](#q111)** Use the Keras `to_categorical` function to one-hot-encode the tags. The dimensionality of your resulting `Y` matrix should be equal to `(# of sentences, max_len, n_tags)`. Run the provided cell to print your results.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-z0JuoWtO5S"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LzwnXzK7tO5T",
    "outputId": "b7472ce7-e1f1-448f-ce37-20d7ad68fe8a"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "print(\"The index of tag 'B-gpe' is: {}\\n\".format(tag2idx[\"B-gpe\"]))\n",
    "print(\"The tag of the last word in Sentence 1: {}\\n\".format(Y[0][-1]))\n",
    "print(\"The shape of the Y array is: {}\".format(Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jJl5Jw_VtO5X"
   },
   "source": [
    "<a id=\"s112\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[1.12:](#q112)** Split the dataset into train and test sets with a 10% test split using `109` for your random state. Assign your training data to the variables `X_tr` and `y_tr` and your test data to the variables `X_te` and `y_te`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2RpQsTOtO5Y",
    "outputId": "b3cc3816-0bcb-4fcb-de5d-0bbceebb8a68"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "print(\n",
    "    \"The shapes of the resulting train-test splits are:\\n\\n\"\n",
    "    \"\\tX_train\\t{}\\n\\ty_train\\t{}\\n\\n\\tX_test\\t{}\\n\\ty_test\\t{}\\n\"\n",
    "    \"\".format(X_tr.shape, y_tr.shape, X_te.shape, y_te.shape)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RzdNQLIPtO5a"
   },
   "source": [
    "<a id=\"part2\"></a>\n",
    "    \n",
    "<!-- <div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\"> -->\n",
    "\n",
    "# PART 2 [ 38 pts ]: Modelling\n",
    "\n",
    "[Return to contents](#contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pk6vsCNKtO5a"
   },
   "source": [
    "<a id=\"part2intro\"></a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iTEEKe9XtO5b"
   },
   "source": [
    "**After preparing the train and test sets, we are ready to build five models:**\n",
    "\n",
    "1. Frequency-based (Baseline) \n",
    "2. Feed forward neural network (FNN)\n",
    "3. Recurrent neural network (RNN)\n",
    "4. Gated recurrent neural network (GRU)\n",
    "5. Bidirectional gated recurrent neural network (Bidirectional GRU)\n",
    "\n",
    "More details are given about the desired architectures in each model's section in [PART 2: Questions](#part2questions) below. The input and output dimensions (i.e. the shapes of the inputs and outputs) will be the same for all models:\n",
    "\n",
    "- input: `[# of sentences, max_len]`\n",
    "- output: `[# of sentences, max_len, n_tags]`\n",
    "\n",
    "Follow the information in each model's section to set up the architecture of the model. And, after training each model, use the given `store_keras_model` function to store the weights and architectures in the `./models` path for later testing. A `load_keras_model` function is also provided to you.\n",
    "\n",
    "A further `plot_training_history` helper function is given to illustrate the training history.\n",
    "\n",
    "**Here are the provided helper functions described above:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JkVtPGkmtO5b"
   },
   "outputs": [],
   "source": [
    "# RUN THIS CELL\n",
    "\n",
    "# Store model\n",
    "def store_keras_model(model, model_name):\n",
    "    \"\"\"Save model and weights as model_name in models folder\n",
    "    \n",
    "    :param model: trained Keras model object\n",
    "    :param model_name: str, name under which to save the model\n",
    "    \"\"\"\n",
    "    # serialize model to JSON\n",
    "    model_json = model.to_json()\n",
    "    if not os.path.exists(\"models\"):\n",
    "        os.mkdir(\"models\")\n",
    "    with open(\"./models/{}.json\".format(model_name), \"w\") as json_file:\n",
    "        json_file.write(model_json)\n",
    "    # serialize weights to HDF5\n",
    "    model.save_weights(\"./models/{}.h5\".format(model_name))\n",
    "    print(\"Saved model to disk\")\n",
    "\n",
    "\n",
    "# Load model \n",
    "def load_keras_model(model_name):\n",
    "    \"\"\"Load model_name from models folder in working directory\n",
    "    \n",
    "    :param model_name: str, name of saved model\n",
    "    :return: Keras model object loaded from disk\n",
    "    \"\"\"\n",
    "    # Load json and create model\n",
    "    json_file = open(\"./models/{}.json\".format(model_name), \"r\")\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    model = tf.keras.models.model_from_json(loaded_model_json)\n",
    "    # Load weights into new model\n",
    "    model.load_weights(\"./models/{}.h5\".format(model_name))\n",
    "    return model\n",
    "\n",
    "\n",
    "# Plot history\n",
    "def plot_training_history(\n",
    "    history, model_title, loss_name=\"Categorical Cross-entropy\"\n",
    "):\n",
    "    \"\"\"Plot training and validation loss over all trained epochs\n",
    "    \n",
    "    :param history: Keras model training history object\n",
    "    :param model_title: str, descriptive model name for use in plot title\n",
    "    :param loss_name: str, name of loss type used in model for labeling\n",
    "                      y-axis (default=\"Categorical Cross-entropy\")\n",
    "    \"\"\"\n",
    "    loss = history.history[\"loss\"]\n",
    "    val_loss = history.history[\"val_loss\"]\n",
    "    epochs = range(1,len(loss)+1)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    plt.plot(epochs, loss, \"k--\", label=\"Training loss\")\n",
    "    plt.plot(epochs, val_loss, \"ko-\", label=\"Validation loss\")\n",
    "    plt.title(\n",
    "        \"{}\\nTraining and Validation Loss\".format(model_title), fontsize=14\n",
    "    )\n",
    "    plt.xlabel(\"Epoch\", fontsize=12)\n",
    "    plt.ylabel(\"{}\".format(loss_name), fontsize=12)\n",
    "    if len(loss)<31:\n",
    "        plt.xticks(range(1,len(loss)+1))\n",
    "    plt.grid(\":\", alpha=0.4)\n",
    "    plt.legend(fontsize=11)\n",
    "    plt.tight_layout()\n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2V-uadsxtO5b"
   },
   "source": [
    "<a id=\"part2questions\"></a>\n",
    "\n",
    "### <div class='exercise'>PART 2: Questions</div> \n",
    "Predict the named entity tag of a word to be its most frequently-seen tag in the training set.\n",
    "[Return to contents](#contents)\n",
    "\n",
    "<a id=\"q21\"></a>\n",
    "\n",
    "**[2.1:](#s21)** **MODEL 1: Baseline**\n",
    "\n",
    "Predict the named entity tag of a word to be its most frequently-seen tag in the training set.\n",
    "\n",
    "- For example, let's say the word \"Apple\" appears 10 times in the training set and 7 times it was tagged as \"Corporate\" and 3 times it was tagged as \"Fruit\". If we encounter the word \"Apple\" in the test set, our Baseline model should predict it as \"Corporate\".\n",
    "\n",
    "**Create an np.array `baseline` of length [n_words]** where the $i$-th element `baseline[i]` is the index of the most commonly seen named entity tag of word $i$ summarized from the training set (e.g. `[16, 16, 16, ..., 0, 16, 16]`). For words that aren't present in the training set, use the default tag `\"O\"`.\n",
    "\n",
    "\n",
    "<a id=\"q22\"></a>\n",
    "\n",
    "**[2.2:](#s22)** **MODEL 2: Feed Forward Neural Network**\n",
    "\n",
    "This model is provided for you. Please pay attention to the architecture of this neural network, especially the input and output dimensionalities and the Embedding layer.\n",
    "\n",
    "<a id=\"q22a\"></a>\n",
    "\n",
    "- **[2.2.a:](#s22a)** Explain what the Embedding layer is and why we need it here.\n",
    "\n",
    "<a id=\"q22b\"></a>\n",
    "\n",
    "- **[2.2.b:](#s22b)** Explain why the Param # of the Embedding layer is 1,758,950 (as shown in `print(model.summary())`).\n",
    "\n",
    "<a id=\"q22c\"></a>\n",
    "\n",
    "- **[2.2.c:](#s22c)** In addition to our models' final results, we often want to inspect intermediate results. For this, we can get outputs from a hidden layer and reduce the dimensionality of those outputs using PCA so that we can visualize them in 2-dimensional space.\n",
    "  - Using the code provided to you in this question, visualize outputs from the Embedding layer in your feed-forward neural network, with one subplot for **B-tags** and one subplot for **I-tags**. (Please note that you should be able to generate these plots by simply running the code provided to you.)\n",
    "  - Comment on the patterns you observe in the plotted output.\n",
    "\n",
    "<a id=\"q23\"></a>\n",
    "\n",
    "**[2.3:](#s23)** **MODEL 3: RNN**\n",
    "\n",
    "Set up a simple RNN model by stacking the following layers in sequence:\n",
    "\n",
    "  - an Input \"layer\"\n",
    "  - a simple Embedding layer transforming integer words into vectors\n",
    "  - a Dropout layer to regularize the model\n",
    "  - a SimpleRNN layer\n",
    "  - a TimeDistributed layer with an inner Dense layer which output dimensionality is equal to `n_tag`\n",
    "    \n",
    "For hyperparameters in this model as well as the subsequent models in 2.4 and 2.5, please use those provided to you in MODEL 2.\n",
    "\n",
    "\n",
    "<a id=\"q23a\"></a>\n",
    "\n",
    "- **[2.3.a:](#s23a)** Define, compile, and train an RNN model. Use the provided code to save the model and plot the training history.\n",
    "\n",
    "\n",
    "<a id=\"q23b\"></a>\n",
    "\n",
    "- **[2.3.b:](#s23b)** Using the functions provided to you [in 2.2.c](#s22c), visualize outputs from the SimpleRNN layer, one subplot for **B-tags** and one subplot for **I-tags**. Comment on the patterns you observed.\n",
    "\n",
    "\n",
    "<a id=\"q24\"></a>\n",
    "\n",
    "**[2.4:](#s24)** **MODEL 4: GRU**\n",
    "\n",
    "\n",
    "<a id=\"q24\"></a>\n",
    "\n",
    "- **[2.4.a:](#s24a)** Briefly explain what a GRU is and how it is different from a simple RNN.\n",
    "\n",
    "\n",
    "<a id=\"q24b\"></a>\n",
    "\n",
    "- **[2.4.b:](#s24b)** Define, compile, and train a GRU architecture by replacing the SimpleRNN cell with a GRU one. Use the provided code to save the model and plot the training history.\n",
    "\n",
    "\n",
    "<a id=\"q24c\"></a>\n",
    "\n",
    "- **[2.4.c:](#s24c)** Using the functions provided to you [in 2.2.c](#s22c), visualize outputs from the GRU layer, one subplot for **B-tags** and one subplot for **I-tags**. Comment on the patterns you observed.\n",
    "\n",
    "\n",
    "<a id=\"q25\"></a>\n",
    "\n",
    "**[2.5:](#s25)** **MODEL 5: Bidirectional GRU**\n",
    "\n",
    "<a id=\"q25a\"></a>\n",
    "\n",
    "- **[2.5.a:](#s25a)** Explain how a Bidirectional GRU differs from the GRU model above.\n",
    "\n",
    "\n",
    "<a id=\"q25b\"></a>\n",
    "\n",
    "- **[2.5.b:](#s25b)** Define, compile, and train a Bidirectional GRU by wrapping your GRU layer in a Bidirectional one. Use the provided code to save the model and plot the training history.\n",
    "\n",
    "\n",
    "<a id=\"q25c\"></a>\n",
    "\n",
    "- **[2.5.c:](#s25c)**  Using the functions provided to you [in 2.2.c](#s22c), visualize outputs from the Bidirectional GRU layer, one subplot for **B-tags** and one subplot for **I-tags**. Comment on the patterns you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAd7ouT7tO5c"
   },
   "source": [
    "<a id=\"part2solutions\"></a>\n",
    "\n",
    "## PART 2: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XsGLSaSLtO5c"
   },
   "source": [
    "<a id=\"s21\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.1:](#q21)** **MODEL 1: Baseline**\n",
    "\n",
    "Predict the named entity tag of a word to be its most frequently-seen tag in the training set.\n",
    "\n",
    "- For example, let's say the word \"Apple\" appears 10 times in the training set and 7 times it was tagged as \"Corporate\" and 3 times it was tagged as \"Fruit\". If we encounter the word \"Apple\" in the test set, our Baseline model should predict it as \"Corporate\".\n",
    "\n",
    "**Create an np.array `baseline` of length [n_words]** where the $i$-th element `baseline[i]` is the index of the most commonly seen named entity tag of word $i$ summarized from the training set (e.g. `[16, 16, 16, ..., 0, 16, 16]`). For words that aren't present in the training set, use the default tag `\"O\"`.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xBD5oL7stO5d"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8wIDHnA8tO5e",
    "outputId": "ec6a6e61-9343-4f9b-f28a-af03d28d2e7c"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "print(\"The baseline array is shape: {}\".format(baseline.shape))\n",
    "print(\n",
    "    \"The training predictions array is shape: {}\\n\".format(baseline[X_tr].shape)\n",
    ")\n",
    "print(\"Sentence:\\n {}\\n\".format([idx2word[w] for w in X_tr[0]]))\n",
    "print(\"Predicted Tags:\\n {}\".format([idx2tag[i] for i in baseline[X_tr[0]]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlSCZ01QtO5f"
   },
   "source": [
    "<a id=\"s22\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.2:](#q22)** **MODEL 2: Feed Forward Neural Network**\n",
    "\n",
    "This model is provided for you. Please pay attention to the architecture of this neural network, especially the input and output dimensionalities and the Embedding layer.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9G7IONHtO5g"
   },
   "source": [
    "### Use these hyperparameters for all NN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PnZ_Dg4dtO5h"
   },
   "outputs": [],
   "source": [
    "n_units = 100\n",
    "drop_rate = .1\n",
    "dim_embed = 50\n",
    "\n",
    "optimizer = \"rmsprop\"\n",
    "loss = \"categorical_crossentropy\"\n",
    "metrics = [\"accuracy\"]\n",
    "\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "validation_split = 0.1\n",
    "verbose = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vylZBUbUtO5h"
   },
   "outputs": [],
   "source": [
    "# Define model\n",
    "model_title = \"Feed-forward Neural Network (FFNN)\"\n",
    "model = tf.keras.Sequential()\n",
    "model.add(\n",
    "    tf.keras.layers.Embedding(\n",
    "        input_dim=n_words, output_dim=dim_embed, input_length=max_len\n",
    "    )\n",
    ")\n",
    "model.add(tf.keras.layers.Dropout(drop_rate))\n",
    "model.add(tf.keras.layers.Dense(n_tags, activation=\"softmax\"))\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iUtAAWL9tO5h",
    "outputId": "537d624a-fdd0-4ad3-8a86-a2065dfb1712"
   },
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LV8xgVWntO5i",
    "outputId": "deca97c3-63f2-4afd-c950-bc393806b8c3"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# Train model\n",
    "history = model.fit(X_tr, y_tr, batch_size=batch_size, epochs=epochs, \n",
    "                    validation_split=validation_split, verbose=verbose)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NW4uML9vtO5j",
    "outputId": "f92cc1e9-51c2-4e6e-9370-90f041f0fb72"
   },
   "outputs": [],
   "source": [
    "store_keras_model(model, \"model_FFNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "fokpW5betO5j",
    "outputId": "670acc19-e8bc-4aa9-f806-9c8c9b71d1a7"
   },
   "outputs": [],
   "source": [
    "plot_training_history(history, model_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tzfduf7CtO5j"
   },
   "source": [
    "<a id=\"s22a\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.2.a:](#q22a)** Explain what the Embedding layer is and why we need it here.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rN8O9aVltO5l"
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T2dh-3LQtO5l"
   },
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "00YQsFkPtO5m"
   },
   "source": [
    "<a id=\"s22b\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.2.b:](#q22b)** Explain why the Param # of the Embedding layer is 1,758,950 (as shown in `print(model.summary())`).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V1rP7uJKtO5m"
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zXhkzdzztO5m"
   },
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"s22c\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.2.c:](#q22c)** In addition to our models' final results, we often want to inspect intermediate results. For this, we can get outputs from a hidden layer and reduce the dimensionality of those outputs using PCA so that we can visualize them in 2-dimensional space.\n",
    "  - Using the code provided to you in this question, visualize outputs from the Embedding layer in your feed-forward neural network, with one subplot for **B-tags** and one subplot for **I-tags**. (Please note that you should be able to generate these plots by simply running the code provided to you.)\n",
    "  - Comment on the patterns you observe in the plotted output.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eIDD4sV5tO5p"
   },
   "outputs": [],
   "source": [
    "def get_hidden_output_PCA(\n",
    "    model, X_test, layer_index, out_dimension, model_title\n",
    "):\n",
    "    \"\"\"Generate hidden layer output PCA transformation\n",
    "    \n",
    "    Captures the output of a specific layer in a Keras model and then \n",
    "    returns a transformed PCA object. Also, prints the variance explained \n",
    "    by the first two principal components.  \n",
    "    \n",
    "    :param model: Keras trained model object\n",
    "    :param X_test: np.array, X test data\n",
    "    :param layer_index: int, index of model layer for which to inspect output\n",
    "    :param out_dimension: int, output embedding dimension of chosen layer\n",
    "    :param model_title: str, descriptive model name for use in printed output\n",
    "    :return: Fitted and transformed sklearn PCA model object\n",
    "    \"\"\"\n",
    "    output = tf.keras.backend.function(\n",
    "        [model.layers[0].input],[model.layers[layer_index].output]\n",
    "    )\n",
    "    hidden_feature = np.array(output([X_test]))\n",
    "    hidden_feature = hidden_feature.reshape(-1, out_dimension)\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    pca_result = pca.fit_transform(hidden_feature)\n",
    "    print(\n",
    "        \"{}\\nHidden features' variance explained by PCA first 2 \"\n",
    "        \"components: {:.4f}\\n\".format(\n",
    "            model_title, np.sum(pca.explained_variance_ratio_)\n",
    "        )\n",
    "    )\n",
    "    return pca_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "al03VPPstO5p"
   },
   "outputs": [],
   "source": [
    "def visualize_B_I(pca_result, y_test, model_title):\n",
    "    \"\"\"Visualize the first 2 PCA dimensions, labeled by tag\n",
    "    \n",
    "    Constructs two subplots showing the first two principal components of\n",
    "    the `B-tags` and `I-tags` in the transformed PCA object provided\n",
    "    \n",
    "    :param pca_result: sklearn PCA object\n",
    "    :param y_test: np.array, y test data\n",
    "    :param model_title: str, descriptive model name for use in plot title\n",
    "    \"\"\"\n",
    "    category = np.argmax(y_test.reshape(-1,18), axis=1)\n",
    "    fig, ax = plt.subplots(1,2, sharey=True, sharex=True, figsize=(11, 6.5)) \n",
    "    titles=[\"B-tags\", \"I-tags\"]\n",
    "    \n",
    "    for i in range(2):\n",
    "        for cat in range(8*i,8*(i+1)):\n",
    "            indices = np.where(category==cat)[0]\n",
    "            ax[i].scatter(\n",
    "                pca_result[indices,0],\n",
    "                pca_result[indices, 1],\n",
    "                label=idx2tag[cat],\n",
    "                s=10,\n",
    "                alpha=0.6,\n",
    "            )\n",
    "        ax[i].legend(markerscale=2, facecolor=\"w\", framealpha=1, fontsize=11)\n",
    "        ax[i].grid(\":\", alpha=0.4)\n",
    "        ax[i].set_xlabel(\"First principal component\", fontsize=12)\n",
    "        ax[i].set_title(titles[i], fontsize=14)\n",
    "    \n",
    "    ax[0].set_ylabel(\"Second principal component\", fontsize=12)\n",
    "    fig.suptitle(\n",
    "        \"Visualization of hidden features on first two PCA components:\\n\"\n",
    "        \"{}\".format(model_title),\n",
    "        fontsize=16,\n",
    "        y=1,\n",
    "        )\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "4Og4hKGBtO5q",
    "outputId": "0d7aaced-b8ba-4416-daa6-caa1d4c37d7e"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "FFNN = load_keras_model(\"model_FFNN\")\n",
    "h_pca = get_hidden_output_PCA(FFNN, X_te, 1, 50, model_title)\n",
    "visualize_B_I(h_pca, y_te, model_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jHsUKqQCtO5r"
   },
   "source": [
    "<a id=\"s23\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.3:](#q23)** **MODEL 3: RNN**\n",
    "\n",
    "Set up a simple RNN model by stacking the following layers in sequence:\n",
    "\n",
    "  - an Input \"layer\"\n",
    "  - a simple Embedding layer transforming integer words into vectors\n",
    "  - a Dropout layer to regularize the model\n",
    "  - a SimpleRNN layer\n",
    "  - a TimeDistributed layer with an inner Dense layer which output dimensionality is equal to `n_tag`\n",
    "    \n",
    "For hyperparameters in this model as well as the subsequent models in 2.4 and 2.5, please use those provided to you in MODEL 2.\n",
    "\n",
    "<a id=\"s23a\"></a>\n",
    "\n",
    "- **[2.3.a:](#q23a)** Define, compile, and train an RNN model. Use the provided code to save the model and plot the training history.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BHp-UQ6EtO5r"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RydDmdREtO5s",
    "outputId": "b0a309f8-9fcb-435c-f47b-8c934b94246c"
   },
   "outputs": [],
   "source": [
    "# Run this cell to save your model\n",
    "store_keras_model(model, \"model_RNN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wxm1OcyctO5s",
    "outputId": "ea50eab8-74d7-43c4-e585-4e461c442f6a"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "-9l0HU-AtO5s",
    "outputId": "4865ddfb-9989-460e-a54a-89f73dba670e"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "plot_training_history(history, model_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G7H7ZUC7tO5t"
   },
   "source": [
    "<a id=\"s23b\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.3.b:](#q23b)** Using the functions provided to you [in 2.2.c](#s22c), visualize outputs from the SimpleRNN layer, one subplot for **B-tags** and one subplot for **I-tags**. Comment on the patterns you observed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "OxEsqynutO5u",
    "outputId": "9fec3ff6-3f6a-4245-ff9e-0f6c99af12a2"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R4FjAIsZ4x7A"
   },
   "source": [
    "**INTERPRETATION:**\n",
    "\n",
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XUL4n0lxtO5y"
   },
   "source": [
    "<a id=\"s24\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.4:](#q24)** **MODEL 4: GRU**\n",
    "\n",
    "<a id=\"s24a\"></a>\n",
    "\n",
    "- **[2.4.a:](#q24a)** Briefly explain what a GRU is and how it is different from a simple RNN.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5D2mTcF-tO5z"
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sP7bkzsTtO50"
   },
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "flg6st9ttO50"
   },
   "source": [
    "<a id=\"s24b\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.4.b:](#q24b)** Define, compile, and train a GRU architecture by replacing the SimpleRNN cell with a GRU one. Use the provided code to save the model and plot the training history.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MbRzj1l0tO51"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vgj_ByLatO51",
    "outputId": "52d131d7-74cd-4cdc-b2ac-5bd08c031a23"
   },
   "outputs": [],
   "source": [
    "# Run this cell to save your model\n",
    "store_keras_model(model, \"model_GRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RAcd_1WmtO51",
    "outputId": "d7b91b0d-95f2-44ea-f476-68e4bfa77b7a"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "n3wgiUTUtO52",
    "outputId": "8fd9cec9-2576-4786-ba77-9f4fd960007d"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "plot_training_history(history, model_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kkhbYwigtO52"
   },
   "source": [
    "<a id=\"s24c\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.4.c:](#q24c)** Using the functions provided to you [in 2.2.c](#s22c), visualize outputs from the GRU layer, one subplot for **B-tags** and one subplot for **I-tags**. Comment on the patterns you observed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "du_qsStZtO53",
    "outputId": "579052cc-9e71-43f1-939a-f03a93c5cb38"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1ZsRvGvtO53"
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AH6DpfyXtO53"
   },
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OYNR9098tO54"
   },
   "source": [
    "<a id=\"s25\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.5:](#q25)** **MODEL 5: Bidirectional GRU**\n",
    "\n",
    "<a id=\"s25a\"></a>\n",
    "\n",
    "- **[2.5.a:](#q25a)** Explain how a Bidirectional GRU differs from the GRU model above.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z6v0xuJYtO54"
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1WXj5RhqtO55"
   },
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DMSpjeHgtO56"
   },
   "source": [
    "<a id=\"s25b\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.5.b:](#q25b)** Define, compile, and train a Bidirectional GRU by wrapping your GRU layer in a Bidirectional one. Use the provided code to save the model and plot the training history.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0Obt6_S7tO57"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fIrn3H-_tO57",
    "outputId": "9761d143-fd15-42bf-e5cd-d4cbd41bf21a"
   },
   "outputs": [],
   "source": [
    "# Run this cell to save your model\n",
    "store_keras_model(model, \"model_BiGRU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Fphp2q9wtO57",
    "outputId": "ea583311-5881-41d7-e33e-a98c4c85783a"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "BigRSFxytO58",
    "outputId": "982c0101-4005-49ff-9905-fabd758efcb8"
   },
   "outputs": [],
   "source": [
    "# Run this cell to show your results\n",
    "plot_training_history(history, model_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NpZC91e7tO58"
   },
   "source": [
    "<a id=\"s25c\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[2.5.c:](#q25c)** Using the functions provided to you [in 2.2.c](#s22c), visualize outputs from the Bidirectional GRU layer, one subplot for **B-tags** and one subplot for **I-tags**. Comment on the patterns you observed.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 540
    },
    "id": "pLfWLOOHtO59",
    "outputId": "4392fdd3-f25d-46eb-a4a5-69ee9317767f"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JK-tIJ5ItO5-"
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "24RXR1ibtO5-"
   },
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zCAnhvIgtO5_"
   },
   "source": [
    "<a id=\"part3\"></a>\n",
    "    \n",
    "<!-- <div class=\"alert alert-block alert-danger\" style=\"color:black;background-color:#E7F4FA\"> -->\n",
    "\n",
    "# PART 3 [ 40 pts ]: Analysis\n",
    "\n",
    "[Return to contents](#contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gyrMLtm6tO6A"
   },
   "source": [
    "<a id=\"part3intro\"></a>\n",
    "\n",
    "## Overview\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o8W4nYgUtO6B"
   },
   "source": [
    "Now that we have built, trained, and visualized our 5 different models, in this section, we will further investigate the results of each model and then seek to improve the results of our most promising model.\n",
    "\n",
    "For this section, we will be using $F_1$ score as our evaluative metric. If you are unfamiliar with this metric, $F_1$ is the harmonic mean of precision and recall. Some basic background on this metric [can be found here](https://en.wikipedia.org/wiki/F1_score)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nURRMAXxtO6C"
   },
   "source": [
    "<a id=\"part3questions\"></a>\n",
    "\n",
    "### <div class='exercise'>PART 3: Questions</div> \n",
    "\n",
    "[Return to contents](#contents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rQdtSzg4tO6C"
   },
   "source": [
    "<a id=\"q31\"></a>\n",
    "\n",
    "**[3.1:](#s31)** For each model, iteratively:\n",
    "\n",
    "- Load the model using the given function `load_keras_model`\n",
    "\n",
    "- Apply the model to the test dataset\n",
    "\n",
    "- Compute an $F_1$ score for each `Tag` and store it \n",
    "\n",
    "\n",
    "<a id=\"q32\"></a>\n",
    "\n",
    "**[3.2:](#s32)** Plot the $F_1$ score per Tag and per model, including all on a single grouped barplot. Include a horizontal reference line at $F_1=0.8$ on your plot.\n",
    "\n",
    "\n",
    "<a id=\"q33\"></a>\n",
    "\n",
    "**[3.3:](#s33)** Briefly discuss the performance of each model.\n",
    "\n",
    "\n",
    "<a id=\"q34\"></a>\n",
    "\n",
    "**[3.4:](#s34)** Which tags have the lowest $F_1$ score? For instance, you may find from the plot above that the test performance on `\"B-art\"` and `\"I-art\"` is very low (just an example, your case may be different). Here is an example when models failed to predict these tags right:\n",
    "\n",
    "<img src=\"data/B_art.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "\n",
    "<a id=\"q35\"></a>\n",
    "\n",
    "**[3.5:](#s35)** Write functions to output another example test sentence in which the lowest scoring tags you identified in 3.4 were predicted wrong in a sentence (be certain to include both `\"B-xxx\"` and `\"I-xxx\"` tags). Store the results in a DataFrame (same format as the above example) and use the styling function provided below to display your DataFrame so that misclassified tags are shown with red text similar to the example provided in the image above. (**Please note:** The red text of your styled DataFrame will not persist between Jupyter notebook sessions. That is perfectly fine and to be expected.)\n",
    "\n",
    "<a id=\"q36\"></a>\n",
    "\n",
    "**[3.6:](#s36)** Choose one of the most promising models you have built and improve that model to achieve an $F_1$ score greater than $0.8$ for as many tags as possible (you have lots of options here, e.g. data balancing, hyperparameter tuning, changing the structure of the NN, using a different optimizer, etc.).\n",
    "\n",
    "\n",
    "<a id=\"q37\"></a>\n",
    "\n",
    "**[3.7:](#s37)** For your final improved model, illustrate your results with a bar plot similarly formatted to the one you created in 3.2, and be certain to include a horizontal line at $F_1=0.8$ to make interpretation easier. Interpret your results and clearly explain why you chose to change certain elements of the model and how effective those adjustments were.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n64h1Za_tO6C"
   },
   "source": [
    "<a id=\"part3solutions\"></a>\n",
    "\n",
    "## PART 3: Solutions\n",
    "\n",
    "[Return to contents](#contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TSkr6c7ptO6D"
   },
   "source": [
    "<a id=\"s31\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[3.1:](#q31)** For each model, iteratively:\n",
    "\n",
    "- Load the model using the given function `load_keras_model`\n",
    "\n",
    "- Apply the model to the test dataset\n",
    "\n",
    "- Compute an $F_1$ score for each `Tag` and store it\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "av6iERgstO6E"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pEzNH6V7tO6F"
   },
   "source": [
    "<a id=\"s32\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[3.2:](#q32)** Plot the $F_1$ score per Tag and per model, including all on a single grouped barplot. Include a horizontal reference line at $F_1=0.8$ on your plot.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9TtWGsQ4tO6F"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToUHerc9tO6G"
   },
   "source": [
    "<a id=\"s33\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[3.3:](#q33)**  Briefly discuss the performance of each model.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ntM8n-bZtO6H"
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5F20qRetO6I"
   },
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGNQY9IitO6I"
   },
   "source": [
    "<a id=\"s34\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[3.4:](#q34)** Which tags have the lowest $F_1$ score? For instance, you may find from the plot above that the test performance on `\"B-art\"` and `\"I-art\"` is very low (just an example, your case may be different). Here is an example when models failed to predict these tags right:\n",
    "\n",
    "<img src=\"data/B_art.png\" alt=\"drawing\" width=\"600\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IU2YF_n5tO6I"
   },
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oZKC4rPytO6J"
   },
   "source": [
    "*Your answer here*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KCxIyEBitO6K"
   },
   "source": [
    "<a id=\"s35\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[3.5:](#q35)** Write functions to output another example test sentence in which the lowest scoring tags you identified in 3.4 were predicted wrong in a sentence (be certain to include both `\"B-xxx\"` and `\"I-xxx\"` tags). Store the results in a DataFrame (same format as the above example) and use the styling function provided below to display your DataFrame so that misclassified tags are shown with red text similar to the example provided in the image above. (**Please note:** The red text of your styled DataFrame will not persist between Jupyter notebook sessions. That is perfectly fine and to be expected.)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2KIOUF_HtO6K"
   },
   "outputs": [],
   "source": [
    "def highlight_errors(s):\n",
    "    \"\"\"Highlights misclassified values when applied to Pandas styler\n",
    "    \n",
    "    See the `pandas.io.formats.style.Styler.apply` documentation\n",
    "    for more information.\n",
    "    \"\"\"\n",
    "    is_max = s == s.y_true\n",
    "    return [\n",
    "        \"\" if v or key==\"Word\" else \"color: red\"\n",
    "        for key, v in is_max.iteritems()\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "76V4ZFeUtO6L"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aal9PtGAtO6M"
   },
   "source": [
    "<a id=\"s36\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[3.6:](#q36)** Choose one of the most promising models you have built and improve that model to achieve an $F_1$ score greater than $0.8$ for as many tags as possible (you have lots of options here, e.g. data balancing, hyperparameter tuning, changing the structure of the NN, using a different optimizer, etc.).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zTanLa6UtO6N"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G8gRe-4ZtO6N"
   },
   "source": [
    "<a id=\"s37\"></a>\n",
    "<div class='exercise-r'>  \n",
    "\n",
    "**[3.7:](#q37)** For your final improved model, illustrate your results with a bar plot similarly formatted to the one you created in 3.2, and be certain to include a horizontal line at $F_1=0.8$ to make interpretation easier. Interpret your results and clearly explain why you chose to change certain elements of the model and how effective those adjustments were.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xYjLQ0jM4x7r"
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETATION:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eFPa29mitO6N"
   },
   "source": [
    "*your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xfMeG4SFdvkB"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "cs109b_hw5_rnn_solutions.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
