{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "# <img style=\"float: left; padding-right: 10px; width: 45px\" src=\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/iacs.png\"> CS109B Data Science 2: Advanced Topics in Data Science \n",
    "## Homework 1 - Smoothers and Generalized Additive Models\n",
    "\n",
    "\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Spring 2021**<br/>\n",
    "**Instructors**: Mark Glickman, Pavlos Protopapas, and Chris Tanner \n",
    "\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>\n",
       "blockquote { background: #AEDE94; }\n",
       "h1 { \n",
       "    padding-top: 25px;\n",
       "    padding-bottom: 25px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "h2 { \n",
       "    padding-top: 10px;\n",
       "    padding-bottom: 10px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "\n",
       "div.exercise {\n",
       "\tbackground-color: #ffcccc;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "div.exercise-r {\n",
       "\tbackground-color: #fce8e8;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "}\n",
       "\n",
       "\n",
       "span.sub-q {\n",
       "\tfont-weight: bold;\n",
       "}\n",
       "div.theme {\n",
       "\tbackground-color: #DDDDDD;\n",
       "\tborder-color: #E9967A; \t\n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 18pt;\n",
       "}\n",
       "div.gc { \n",
       "\tbackground-color: #AEDE94;\n",
       "\tborder-color: #E9967A; \t \n",
       "\tborder-left: 5px solid #800080; \n",
       "\tpadding: 0.5em;\n",
       "\tfont-size: 12pt;\n",
       "}\n",
       "p.q1 { \n",
       "    padding-top: 5px;\n",
       "    padding-bottom: 5px;\n",
       "    text-align: left; \n",
       "    padding-left: 5px;\n",
       "    background-color: #EEEEEE; \n",
       "    color: black;\n",
       "}\n",
       "header {\n",
       "   padding-top: 35px;\n",
       "    padding-bottom: 35px;\n",
       "    text-align: left; \n",
       "    padding-left: 10px;\n",
       "    background-color: #DDDDDD; \n",
       "    color: black;\n",
       "}\n",
       "</style>\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#PLEASE RUN THIS CELL \n",
    "import requests\n",
    "from IPython.core.display import HTML\n",
    "styles = requests.get(\"https://raw.githubusercontent.com/Harvard-IACS/2018-CS109A/master/content/styles/cs109.css\").text\n",
    "HTML(styles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### INSTRUCTIONS\n",
    "\n",
    "- To submit your assignment, please follow the instructions on Canvas.\n",
    "- Please restart the kernel and run the entire notebook again before you submit.\n",
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "### Please use the libraries below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from pygam import LinearGAM, s, f\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Seaborn visualization library\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "\n",
    "<hr style=\"height:2pt\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Question 1 [50 pts]: Modeling seasonality of Airbnb prices </b></div>\n",
    "\n",
    "In this problem, the task is to build a regression model to predict the price of an Airbnb rental for a given date. The data are provided in `calendar_train.csv` and `calendar_test.csv`, which contain availability and price data for a sample of Airbnb units in the Boston area from 2017 to 2018, about 4 observations per day in each set.\n",
    "\n",
    "**1.1** Start by loading the data using pandas.  \n",
    "*Hint*: You likely want to have pandas parse the `date` column as a datetime object via the `parse_dates` argument of `pd.read_csv`\n",
    "\n",
    "\n",
    "**1.2** Visualize the average price by month and day of the week (i.e., Monday, Tuesday, etc.) for the training set. Point out any trends you notice and explain whether or not they make sense.\n",
    "\n",
    "\n",
    "**1.3** Explore different regression models. Fit a regression model that uses the date as a predictor and predicts the price of an Airbnb rental on that date. In this section, you should ignore all other predictors besides the date. Fit the following models on the training set, and compare the $R^2$ of the fitted models on the test set. Include plots of the fitted models for each method. Make sure to fit your model on *all training set observations*. Do not average or otherwise combine the data before fitting.\n",
    "\n",
    "\n",
    "*Important*: Convert the `date` column into a numerical variable by taking the difference in days between each date and the earliest date in the column.\n",
    "\n",
    "* **1.3.1** Fit simple polynomial models of degree 2, 3, 5, and 8 via the `statsmodels` library to the training data. Provide train and test R^2 scores and provide plot(s) of a) the daily averages and b) each model's predictions.\n",
    "\n",
    "* **1.3.2** You should see that the degree 8 polynomial's predictions are awful- either nonsensically near zero [or far too large] at many input values. This isn't just simple overfitting. What is going wrong in this model, and how might it be addressed?\n",
    "\n",
    "* **1.3.3** Fit a penalized B-spline using `pygam` with the smoothness parameter chosen by cross-validation on the training set.  Again, provide the train and test scores of the best-performing model and plot its predictions.\n",
    "\n",
    "* **1.3.4** Of the models, which performs the best? What is the effect of the tuning parameters (degree and smoothness penalty)?\n",
    "\n",
    "\n",
    "**1.4** It is possible/likely that prices on weekends (Friday nights and Saturday nights) are systematically higher than prices on weekdays, and that including this aspect of the data-generating process in our model will produce a better fit. Create a binary indicator of weekend versus non-weekend, and include it in your additive model based on `pygam`.  How does it impact the model's performance?  \n",
    "\n",
    "*Hint*: include a categorical variable in a GAM by importing and using `pygam.f` in the same way you've used `pygam.s` for continuous variables.\n",
    "\n",
    "\n",
    "**1.5** You may have noticed from your scatterplots of average price versus day on the training set that there are a few days with abnormally high average prices. Sort the training data in decreasing order of average price, extracting the 10 most expensive dates. Why are the prices on these days so high? Is it something about the days themselves, noise, an artifact of data collection, or something else?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.1** Start by loading the data using pandas.\n",
    "*Hint*: You likely want to have pandas parse the `date` column as a datetime object via the `parse_dates` argument of `pd.read_csv`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.2** Visualize the average price by month and day of the week (i.e., Monday, Tuesday, etc.) for the training set. Point out any trends you notice and explain whether or not they make sense.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.3** Explore different regression models. Fit a regression model that uses the date as a predictor and predicts the price of an Airbnb rental on that date. In this section, you should ignore all other predictors besides the date. Fit the following models on the training set, and compare the $R^2$ of the fitted models on the test set. Include plots of the fitted models for each method. Make sure to fit your model on *all training set observations*. Do not average or otherwise combine the data before fitting.\n",
    "\n",
    "\n",
    "*Important*: Convert the `date` column into a numerical variable by taking the difference in days between each date and the earliest date in the column.\n",
    "\n",
    "**1.3.1** Fit simple polynomial models of degree 2, 3, 5, and 8 via the `statsmodels` library to the training data. Provide train and test R^2 scores and provide plot(s) of a) the daily averages and b) each model's predictions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.3.2** You should see that the degree 8 polynomial's predictions are awful- either nonsensically near zero [or far too large] at many input values. This isn't just simple overfitting. What is going wrong in this model, and how might it be addressed?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.3.3** Fit a penalized B-spline using `pygam` with the smoothness parameter chosen by cross-validation on the training set.  Again, provide the train and test scores of the best-performing model and plot its predictions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.3.4** Of the models, which performs the best? What is the effect of the tuning parameters (degree and smoothness penalty)?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.4",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.4** It is possible/likely that prices on weekends (Friday nights and Saturday nights) are systematically higher than prices on weekdays, and that including this aspect of the data-generating process in our model will produce a better fit. Create a binary indicator of weekend versus non-weekend, and include it in your additive model based on `pygam`.  How does it impact the model's performance?\n",
    "\n",
    "*Hint*: include a categorical variable in a GAM by importing and using `pygam.f` in the same way you've used `pygam.s` for continuous variables.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "1.5",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**1.5** You may have noticed from your scatterplots of average price versus day on the training set that there are a few days with abnormally high average prices. Sort the training data in decreasing order of average price, extracting the 10 most expensive dates. Why are the prices on these days so high? Is it something about the days themselves, noise, an artifact of data collection, or something else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "<div class='exercise'><b> Question 2 [50 pts]: Predicting Airbnb Rental Price Through Listing Features </b></div>\n",
    "\n",
    "In this problem, we'll continue our exploration of Airbnb data by predicting price based on listing features. The data can be found in `listings_train.csv` and `listings_test.csv`.\n",
    "\n",
    "**2.1** First, visualize the relationship between each of the predictors and the response variable. Does it appear that some of the predictors have a nonlinear relationship with the response variable?\n",
    "\n",
    "\n",
    "**2.2** Fit the following models on the training set and compare the $R^2$ score of the fitted models on the test set:\n",
    "* Linear regression\n",
    "* Regression with polynomial basis functions of degree 3 (i.e. basis functions $x, x^2, x^3$ for each predictor $x$) for quantitative predictors.\n",
    "\n",
    "**2.3** Do you expect any advantage in fitting an additive model to these data, compared to the above models?\n",
    "\n",
    "**2.4** Fit an additive model using the `pygam` library to the training set, and compare the test $R^2$ of the fitted model to the above models. You may use a penalized B-spline basis function on each predictor, tuned using cross-validation on the training set.\n",
    "\n",
    "**2.5** Plot and examine the smooth of each predictor for the fitted additive model. What are some useful insights conveyed by these plots?\n",
    "\n",
    "**2.6** Using the outputs and insights from part 1), discuss the most important variables in the driving prices, and give advide to a frugal traveller hoping to visit Boston."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.1",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.1** First, visualize the relationship between each of the predictors and the response variable. Does it appear that some of the predictors have a nonlinear relationship with the response variable?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.2",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.2** Fit the following models on the training set and compare the $R^2$ score of the fitted models on the test set:\n",
    "* Linear regression\n",
    "* Regression with polynomial basis functions of degree 3 (i.e. basis functions $x, x^2, x^3$ for each predictor $x$) for quantitative predictors.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.3",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.3** Do you expect any advantage in fitting an additive model to these data, compared to the above models?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.4",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.4** Fit an additive model using the `pygam` library to the training set, and compare the test $R^2$ of the fitted model to the above models. You may use a penalized B-spline basis function on each predictor, tuned using cross-validation on the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.5",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.5** Plot and examine the smooth of each predictor for the fitted additive model. What are some useful insights conveyed by these plots?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "deletable": false
   },
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "autograde": "2.6",
    "deletable": false,
    "editable": false
   },
   "source": [
    "**2.6** Using the outputs and insights from part 1), discuss the most important variables in the driving prices, and give advide to a frugal traveller hoping to visit Boston."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false
   },
   "source": [
    "*Your answer here*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
